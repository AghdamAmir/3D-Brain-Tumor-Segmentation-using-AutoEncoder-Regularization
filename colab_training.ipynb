{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSbowLgssh6L",
        "outputId": "b4d453c9-b32f-4c06-89a3-a61485959a39"
      },
      "outputs": [],
      "source": [
        "!pip install nilearn\n",
        "!pip install monai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBRVQ3GWrNb3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nibabel as nib\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.modules.loss import _Loss \n",
        "import glob\n",
        "import numpy as np\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar -xvf path-to-tar-file -C path-to-extract-files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sol_Bmy90B1l"
      },
      "source": [
        "# Important Params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwJKzutp0BFi"
      },
      "outputs": [],
      "source": [
        "inChans = 4\n",
        "input_shape = (4, 160, 240, 240)\n",
        "seg_outChans = 3\n",
        "activation = \"relu\"\n",
        "normalizaiton = \"group_normalization\"\n",
        "VAE_enable = True\n",
        "train_img_root = '/content/Task01_BrainTumour/imagesTr'\n",
        "train_label_root = '/content/Task01_BrainTumour/labelsTr'\n",
        "val_img_root = '/content/Task01_BrainTumour/imagesTr'\n",
        "val_label_root = '/content/Task01_BrainTumour/labelsTr'\n",
        "train_batch_size = 1\n",
        "val_batch_size = 1\n",
        "checkpoint_path = '/content'\n",
        "epochs = 100\n",
        "lr = 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZyqhWl8rFro"
      },
      "source": [
        "# NVNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLkc-VaxrJr3"
      },
      "outputs": [],
      "source": [
        "class DownSampling(nn.Module):\n",
        "    # 3x3x3 convolution and 1 padding as default\n",
        "    def __init__(self, inChans, outChans, stride=2, kernel_size=3, padding=1, dropout_rate=None):\n",
        "        super(DownSampling, self).__init__()\n",
        "        \n",
        "        self.dropout_flag = False\n",
        "        self.conv1 = nn.Conv3d(in_channels=inChans, \n",
        "                     out_channels=outChans, \n",
        "                     kernel_size=kernel_size, \n",
        "                     stride=stride,\n",
        "                     padding=padding,\n",
        "                     bias=False)\n",
        "        if dropout_rate is not None:\n",
        "            self.dropout_flag = True\n",
        "            self.dropout = nn.Dropout3d(dropout_rate,inplace=True)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        if self.dropout_flag:\n",
        "            out = self.dropout(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpfPmYRHrSbp"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    '''\n",
        "    Encoder block\n",
        "    '''\n",
        "    def __init__(self, inChans, outChans, stride=1, padding=1, num_groups=8, activation=\"relu\", normalizaiton=\"group_normalization\"):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        \n",
        "        if normalizaiton == \"group_normalization\":\n",
        "            self.norm1 = nn.GroupNorm(num_groups=num_groups, num_channels=inChans)\n",
        "            self.norm2 = nn.GroupNorm(num_groups=num_groups, num_channels=inChans)\n",
        "        if activation == \"relu\":\n",
        "            self.actv1 = nn.ReLU(inplace=True)\n",
        "            self.actv2 = nn.ReLU(inplace=True)\n",
        "        elif activation == \"elu\":\n",
        "            self.actv1 = nn.ELU(inplace=True)\n",
        "            self.actv2 = nn.ELU(inplace=True)\n",
        "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=3, stride=stride, padding=padding)\n",
        "        self.conv2 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=3, stride=stride, padding=padding)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        \n",
        "        out = self.norm1(x)\n",
        "        out = self.actv1(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.actv2(out)\n",
        "        out = self.conv2(out)\n",
        "        \n",
        "        out += residual\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FrmnGpnrV0h"
      },
      "outputs": [],
      "source": [
        "class LinearUpSampling(nn.Module):\n",
        "    '''\n",
        "    Trilinear interpolate to upsampling\n",
        "    '''\n",
        "    def __init__(self, inChans, outChans, scale_factor=2, mode=\"trilinear\", align_corners=True):\n",
        "        super(LinearUpSampling, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "        self.align_corners = align_corners\n",
        "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1)\n",
        "        self.conv2 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1)\n",
        "    \n",
        "    def forward(self, x, skipx=None):\n",
        "        out = self.conv1(x)\n",
        "        # out = self.up1(out)\n",
        "        out = nn.functional.interpolate(out, scale_factor=self.scale_factor, mode=self.mode, align_corners=self.align_corners)\n",
        "\n",
        "        if skipx is not None:\n",
        "            out = torch.cat((out, skipx), 1)\n",
        "            out = self.conv2(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRph437ArXrn"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    '''\n",
        "    Decoder block\n",
        "    '''\n",
        "    def __init__(self, inChans, outChans, stride=1, padding=1, num_groups=8, activation=\"relu\", normalizaiton=\"group_normalization\"):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        \n",
        "        if normalizaiton == \"group_normalization\":\n",
        "            self.norm1 = nn.GroupNorm(num_groups=num_groups, num_channels=outChans)\n",
        "            self.norm2 = nn.GroupNorm(num_groups=num_groups, num_channels=outChans)\n",
        "        if activation == \"relu\":\n",
        "            self.actv1 = nn.ReLU(inplace=True)\n",
        "            self.actv2 = nn.ReLU(inplace=True)\n",
        "        elif activation == \"elu\":\n",
        "            self.actv1 = nn.ELU(inplace=True)\n",
        "            self.actv2 = nn.ELU(inplace=True)            \n",
        "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=3, stride=stride, padding=padding)\n",
        "        self.conv2 = nn.Conv3d(in_channels=outChans, out_channels=outChans, kernel_size=3, stride=stride, padding=padding)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        \n",
        "        out = self.norm1(x)\n",
        "        out = self.actv1(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.norm2(out)\n",
        "        out = self.actv2(out)\n",
        "        out = self.conv2(out)\n",
        "        \n",
        "        out += residual\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPon7LbtraQn"
      },
      "outputs": [],
      "source": [
        "class OutputTransition(nn.Module):\n",
        "    '''\n",
        "    Decoder output layer \n",
        "    output the prediction of segmentation result\n",
        "    '''\n",
        "    def __init__(self, inChans, outChans):\n",
        "        super(OutputTransition, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=outChans, kernel_size=1)\n",
        "        self.actv1 = torch.sigmoid\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.actv1(self.conv1(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc_PjEd1rtf-"
      },
      "outputs": [],
      "source": [
        "def VDraw(x):\n",
        "    x = torch.abs(x)\n",
        "    # Generate a Gaussian distribution with the given mean(128-d) and std(128-d)\n",
        "    return torch.distributions.normal.Normal(x[:,:128], x[:,128:]).sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAGAtiBtrcGf"
      },
      "outputs": [],
      "source": [
        "class VDResampling(nn.Module):\n",
        "    '''\n",
        "    Variational Auto-Encoder Resampling block\n",
        "    '''\n",
        "    def __init__(self, inChans=256, outChans=256, dense_features=(10,12,8), stride=2, kernel_size=3, padding=1, activation=\"relu\", normalizaiton=\"group_normalization\"):\n",
        "        super(VDResampling, self).__init__()\n",
        "        \n",
        "        midChans = int(inChans / 2)\n",
        "        self.dense_features = dense_features\n",
        "        if normalizaiton == \"group_normalization\":\n",
        "            self.gn1 = nn.GroupNorm(num_groups=8,num_channels=inChans)\n",
        "        if activation == \"relu\":\n",
        "            self.actv1 = nn.ReLU(inplace=True)\n",
        "            self.actv2 = nn.ReLU(inplace=True)\n",
        "        elif activation == \"elu\":\n",
        "            self.actv1 = nn.ELU(inplace=True)\n",
        "            self.actv2 = nn.ELU(inplace=True)\n",
        "        self.conv1 = nn.Conv3d(in_channels=inChans, out_channels=16, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.dense1 = nn.Linear(in_features=16*dense_features[0]*dense_features[1]*dense_features[2], out_features=inChans)\n",
        "        self.dense2 = nn.Linear(in_features=midChans, out_features=midChans*dense_features[0]*dense_features[1]*dense_features[2])\n",
        "        self.up0 = LinearUpSampling(midChans,outChans)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.gn1(x)\n",
        "        out = self.actv1(out)\n",
        "        out = self.conv1(out)\n",
        "        out = out.view(-1, self.num_flat_features(out))\n",
        "        out_vd = self.dense1(out)\n",
        "        distr = out_vd \n",
        "        out = VDraw(out_vd)\n",
        "        out = self.dense2(out)\n",
        "        out = self.actv2(out)\n",
        "        out = out.view((1, 128, self.dense_features[0],self.dense_features[1],self.dense_features[2]))\n",
        "        out = self.up0(out)\n",
        "        \n",
        "        return out, distr\n",
        "            \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "            \n",
        "        return num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXWcFwkrrelZ"
      },
      "outputs": [],
      "source": [
        "class VDecoderBlock(nn.Module):\n",
        "    '''\n",
        "    Variational Decoder block\n",
        "    '''\n",
        "    def __init__(self, inChans, outChans, activation=\"relu\", normalizaiton=\"group_normalization\", mode=\"trilinear\"):\n",
        "        super(VDecoderBlock, self).__init__()\n",
        "\n",
        "        self.up0 = LinearUpSampling(inChans, outChans, mode=mode)\n",
        "        self.block = DecoderBlock(outChans, outChans, activation=activation, normalizaiton=normalizaiton)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.up0(x)\n",
        "        out = self.block(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9vUMCuGrwtZ"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    '''\n",
        "    Variational Auto-Encoder : to group the features extracted by Encoder\n",
        "    '''\n",
        "    def __init__(self, inChans=256, outChans=4, dense_features=(10,12,8), activation=\"relu\", normalizaiton=\"group_normalization\", mode=\"trilinear\"):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.vd_resample = VDResampling(inChans=inChans, outChans=inChans, dense_features=dense_features)\n",
        "        self.vd_block2 = VDecoderBlock(inChans, inChans//2)\n",
        "        self.vd_block1 = VDecoderBlock(inChans//2, inChans//4)\n",
        "        self.vd_block0 = VDecoderBlock(inChans//4, inChans//8)\n",
        "        self.vd_end = nn.Conv3d(inChans//8, outChans, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out, distr = self.vd_resample(x)\n",
        "        out = self.vd_block2(out)\n",
        "        out = self.vd_block1(out)\n",
        "        out = self.vd_block0(out)\n",
        "        out = self.vd_end(out)\n",
        "\n",
        "        return out, distr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhDdpYMHryoz"
      },
      "outputs": [],
      "source": [
        "class NvNet(nn.Module):\n",
        "    def __init__(self, inChans, input_shape, seg_outChans, activation, normalizaiton, VAE_enable, mode):\n",
        "        super(NvNet, self).__init__()\n",
        "        \n",
        "        # some critical parameters\n",
        "        self.inChans = inChans\n",
        "        self.input_shape = input_shape\n",
        "        self.seg_outChans = seg_outChans\n",
        "        self.activation = activation\n",
        "        self.normalizaiton = normalizaiton\n",
        "        self.mode = mode\n",
        "        self.VAE_enable = VAE_enable\n",
        "        \n",
        "        # Encoder Blocks\n",
        "        self.in_conv0 = DownSampling(inChans=self.inChans, outChans=32, stride=1,dropout_rate=0.2)\n",
        "        self.en_block0 = EncoderBlock(32, 32, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_down1 = DownSampling(32, 64)\n",
        "        self.en_block1_0 = EncoderBlock(64, 64, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_block1_1 = EncoderBlock(64, 64, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_down2 = DownSampling(64, 128)\n",
        "        self.en_block2_0 = EncoderBlock(128, 128, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_block2_1 = EncoderBlock(128, 128, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_down3 = DownSampling(128, 256)\n",
        "        self.en_block3_0 = EncoderBlock(256, 256, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_block3_1 = EncoderBlock(256, 256, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_block3_2 = EncoderBlock(256, 256, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.en_block3_3 = EncoderBlock(256, 256, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        \n",
        "        # Decoder Blocks\n",
        "        self.de_up2 =  LinearUpSampling(256, 128, mode=self.mode)\n",
        "        self.de_block2 = DecoderBlock(128, 128, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.de_up1 =  LinearUpSampling(128, 64, mode=self.mode)\n",
        "        self.de_block1 = DecoderBlock(64, 64, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.de_up0 =  LinearUpSampling(64, 32, mode=self.mode)\n",
        "        self.de_block0 = DecoderBlock(32, 32, activation=self.activation, normalizaiton=self.normalizaiton)\n",
        "        self.de_end = OutputTransition(32, self.seg_outChans)\n",
        "        \n",
        "        # Variational Auto-Encoder\n",
        "        if self.VAE_enable:\n",
        "            self.dense_features = (self.input_shape[1]//16, self.input_shape[2]//16, self.input_shape[3]//16)\n",
        "            self.vae = VAE(256, outChans=self.inChans, dense_features=self.dense_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_init = self.in_conv0(x)\n",
        "        out_en0 = self.en_block0(out_init)\n",
        "        out_en1 = self.en_block1_1(self.en_block1_0(self.en_down1(out_en0))) \n",
        "        out_en2 = self.en_block2_1(self.en_block2_0(self.en_down2(out_en1)))\n",
        "        out_en3 = self.en_block3_3(\n",
        "            self.en_block3_2(\n",
        "                self.en_block3_1(\n",
        "                    self.en_block3_0(\n",
        "                        self.en_down3(out_en2)))))\n",
        "        \n",
        "        out_de2 = self.de_block2(self.de_up2(out_en3, out_en2))\n",
        "        out_de1 = self.de_block1(self.de_up1(out_de2, out_en1))\n",
        "        out_de0 = self.de_block0(self.de_up0(out_de1, out_en0))\n",
        "        out_end = self.de_end(out_de0)\n",
        "        \n",
        "        if self.VAE_enable:\n",
        "            out_vae, out_distr = self.vae(out_en3)\n",
        "            out_final = torch.cat((out_end, out_vae), 1)\n",
        "            return out_final, out_distr\n",
        "        \n",
        "        return out_end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL7QLfrZuVl7"
      },
      "source": [
        "# Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obAIV2hc8pmY"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import (\n",
        "    Compose, RandFlipd, Affined, Rand3DElastic, ToTensord, AddChanneld, DivisiblePadd\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99GzPm9v-jS8"
      },
      "outputs": [],
      "source": [
        "train_transforms = Compose([\n",
        "                            AddChanneld(['label']),\n",
        "                            RandFlipd(['image', 'label'], prob=0.5, spatial_axis=0),\n",
        "                            RandFlipd(['image', 'label'], prob=0.5, spatial_axis=1),\n",
        "                            DivisiblePadd(k=8, keys=['image', 'label']),\n",
        "                            ToTensord(['image', 'label'])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4EPeY_JV4h6"
      },
      "outputs": [],
      "source": [
        "val_transforms = Compose([\n",
        "                            AddChanneld(['label']),\n",
        "                            DivisiblePadd(k=8, keys=['image', 'label']),\n",
        "                            ToTensord(['image', 'label'])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OyAe6YdEL0K"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_4Tsp21ACXL"
      },
      "outputs": [],
      "source": [
        "class BraTSDataSet(torch.utils.data.Dataset):\n",
        "  def __init__(self, img_root, label_root, transform=None):\n",
        "    self.img_root = img_root\n",
        "    self.label_root = label_root\n",
        "    self.transform = transform\n",
        "    self.img_list = glob.glob(os.path.join(img_root, '*.nii.gz'))\n",
        "    self.label_list = glob.glob(os.path.join(label_root, '*.nii.gz'))\n",
        "    assert len(self.img_list)==len(self.label_list), \"Some Data Samples are missing!\"\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_list)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = self.img_list[idx]\n",
        "    label = self.label_list[idx]\n",
        "    image = nib.load(image).get_fdata().astype(np.float32)\n",
        "    label = nib.load(label).get_fdata()\n",
        "    image = np.transpose(image)\n",
        "    label = np.transpose(label)\n",
        "    item_dict= {'image': image, 'label': label}\n",
        "    if self.transform:\n",
        "      item_dict = self.transform(item_dict)\n",
        "    else:\n",
        "      image = torchvision.transforms.ToTensor()(image)\n",
        "      label = torchvision.transforms.ToTensor()(label)\n",
        "      item_dict['image'] = image\n",
        "      item_dict['label'] = label\n",
        "    return item_dict['image'], item_dict['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoONSdZmGs9V"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06fYhp3vvsUm"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiresdPsvujc"
      },
      "outputs": [],
      "source": [
        "class SoftDiceLoss(_Loss):\n",
        "    '''\n",
        "    Soft_Dice = 2*|dot(A, B)| / (|dot(A, A)| + |dot(B, B)| + eps)\n",
        "    eps is a small constant to avoid zero division, \n",
        "    '''\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true, eps=1e-8):\n",
        "        intersection = torch.sum(torch.mul(y_pred, y_true)) \n",
        "        union = torch.sum(torch.mul(y_pred, y_pred)) + torch.sum(torch.mul(y_true, y_true)) + eps\n",
        "\n",
        "        dice = 2 * intersection / union \n",
        "        dice_loss = 1 - dice\n",
        "\n",
        "        return dice_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPZlVs65v6rI"
      },
      "outputs": [],
      "source": [
        "class CustomKLLoss(_Loss):\n",
        "    '''\n",
        "    KL_Loss = (|dot(mean , mean)| + |dot(std, std)| - |log(dot(std, std))| - 1) / N\n",
        "    N is the total number of image voxels\n",
        "    '''\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomKLLoss, self).__init__()\n",
        "\n",
        "    def forward(self, mean, std):\n",
        "        return torch.mean(torch.mul(mean, mean)) + torch.mean(torch.mul(std, std)) - torch.mean(torch.log(torch.mul(std, std))) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVkkeETGv9IJ"
      },
      "outputs": [],
      "source": [
        "class CombinedLoss(_Loss):\n",
        "    '''\n",
        "    Combined_loss = Dice_loss + k1 * L2_loss + k2 * KL_loss\n",
        "    As default: k1=0.1, k2=0.1\n",
        "    '''\n",
        "    def __init__(self, k1=0.1, k2=0.1):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.k1 = k1\n",
        "        self.k2 = k2\n",
        "        self.dice_loss = SoftDiceLoss()\n",
        "        self.l2_loss = nn.MSELoss()\n",
        "        self.kl_loss = CustomKLLoss()\n",
        "\n",
        "    def forward(self, seg_y_pred, seg_y_true, rec_y_pred, rec_y_true, y_mid):\n",
        "        est_mean, est_std = (y_mid[:, :128], y_mid[:, 128:])\n",
        "        dice_loss = self.dice_loss(seg_y_pred, seg_y_true)\n",
        "        l2_loss = self.l2_loss(rec_y_pred, rec_y_true)\n",
        "        kl_div = self.kl_loss(est_mean, est_std)\n",
        "        combined_loss = dice_loss + self.k1 * l2_loss + self.k2 * kl_div\n",
        "        #print(\"dice_loss:%.4f, L2_loss:%.4f, KL_div:%.4f, combined_loss:%.4f\"%(dice_loss,l2_loss,kl_div,combined_loss))\n",
        "        \n",
        "        return combined_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJLNaJXaKUs9"
      },
      "source": [
        "# Varriables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQDg7DsxKUW1"
      },
      "outputs": [],
      "source": [
        "# Data Load\n",
        "train_dataset = BraTSDataSet(img_root=train_img_root, label_root=train_label_root, transform=train_transforms)\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size) #num_workers=os.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvxpZ1FEQpi6"
      },
      "outputs": [],
      "source": [
        "val_dataset = BraTSDataSet(img_root=val_img_root, label_root=val_label_root, transform=val_transforms)\n",
        "val_loader = DataLoader(val_dataset, batch_size=val_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEF21LRKN6vx"
      },
      "outputs": [],
      "source": [
        "net = NvNet(inChans, input_shape, seg_outChans, activation, normalizaiton, VAE_enable, mode='trilinear')\n",
        "if torch.cuda.is_available(): net = net.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS5v-1qgSMci"
      },
      "outputs": [],
      "source": [
        "criterion = CombinedLoss(k1=0.1, k2=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTT1VLIXcxVX"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNomyD49TXRk"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "best_loss = -math.inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27N_JUq10PJh"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "so2xVei4H9J0",
        "outputId": "f154d720-bcd0-4c20-8188-15442c436d73"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    # Train Model\n",
        "    print('\\n\\n\\nEpoch: {}\\n<Train>'.format(epoch))\n",
        "    net.train(True)\n",
        "    loss = 0\n",
        "    lr = lr * (0.5 ** (epoch // 4))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr\n",
        "    torch.set_grad_enabled(True)\n",
        "    for idx, (img, label) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "          img, label = img.cuda(), label.cuda()\n",
        "        pred = net(img)\n",
        "        seg_y_pred, rec_y_pred, y_mid = pred[0][:,:seg_outChans,:,:,:], pred[0][:,seg_outChans:,:,:,:], pred[1]\n",
        "        batch_loss = criterion(seg_y_pred, label, rec_y_pred, img, y_mid)\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        loss += float(batch_loss)\n",
        "    log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f' %(epoch, loss/(idx+1))])\n",
        "    print(log_msg)\n",
        "\n",
        "\n",
        "    # Validate Model\n",
        "    print('\\n\\n<Validation>')\n",
        "    net.eval()\n",
        "    for module in net.module.modules():\n",
        "        if isinstance(module, torch.nn.modules.Dropout2d):\n",
        "            module.train(True)\n",
        "        elif isinstance(module, torch.nn.modules.Dropout):\n",
        "            module.train(True)\n",
        "        else:\n",
        "            pass\n",
        "    loss = 0\n",
        "    torch.set_grad_enabled(False)\n",
        "    for idx, (img, label) in enumerate(val_loader):\n",
        "      if torch.cuda.is_available():\n",
        "        img, label = img.cuda(), label.cuda()\n",
        "        pred = net(img)\n",
        "        seg_y_pred, rec_y_pred, y_mid = pred[0][:,:seg_outChans,:,:,:], pred[0][:,seg_outChans:,:,:,:], pred[1]\n",
        "        batch_loss = criterion(seg_y_pred, label, rec_y_pred, img, y_mid)\n",
        "        loss += float(batch_loss)\n",
        "    log_msg = '\\n'.join(['Epoch: %d  Loss: %.5f' %(epoch, loss/(idx+1))])\n",
        "    print(log_msg)\n",
        "\n",
        "    # Save Model\n",
        "    if loss <= best_loss:\n",
        "        torch.save(os.path.join(checkpoint_path, f'epoch:{epoch}_loss{loss}.tar'))\n",
        "        best_loss = loss\n",
        "        print(\"Saving...\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Untitled2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
